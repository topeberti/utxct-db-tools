{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a67809",
   "metadata": {},
   "source": [
    "# Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373b1660",
   "metadata": {},
   "source": [
    "Notebook to load dataset data into the database. This notebook demonstrates how to create dataset entries with their associated metadata and measurement relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60afb71",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64a52866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "# Import a folder in the parent directory\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import dbtools.dbtools as qrs\n",
    "import dbtools.load as load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde30b42",
   "metadata": {},
   "source": [
    "## Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b005509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Connect to the PostgreSQL database\n",
    "    conn = qrs.connect()\n",
    "    print(\"Connected to the database\")\n",
    "\n",
    "except (Exception, psycopg2.DatabaseError) as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33d95e7",
   "metadata": {},
   "source": [
    "## Dataset Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3f8c1d",
   "metadata": {},
   "source": [
    "The `load_dataset` function creates a new dataset entry in the database with associated metadata and measurement relationships.\n",
    "\n",
    "Parameters:\n",
    "- `file_path`: The path to the dataset file\n",
    "- `rows`: Number of rows in the dataset\n",
    "- `patch_size`: Patch size of the dataset\n",
    "- `targets`: List of targets for the dataset\n",
    "- `reconstruction_shape`: Shape to see the dataset as an image\n",
    "- `registration_ids`: List of the ids of the registrations used to create this dataset\n",
    "- `description`: Optional dataset description\n",
    "- `additional_metadata`: Optional list of dictionaries with metadata\n",
    "\n",
    "Each metadata dictionary should contain:\n",
    "- `key`: The name of the metadata field\n",
    "- `value`: The value of the metadata\n",
    "- `type`: The type or unit of the metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61a7a8b",
   "metadata": {},
   "source": [
    "## Dataset with Additional Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5884f7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset from '\\\\192.168.10.106\\imdea\\DataDriven_UT_AlbertoVicente\\04_ML_data\\Juan Ignacio\\JI_4\\MonoElement\\patch_vs_volfrac_3.csv' loaded with ID: 66\n",
      "Dataset with additional metadata loaded with ID: 66\n"
     ]
    }
   ],
   "source": [
    "# Define another dataset file path (replace with an actual file path in your system)\n",
    "dataset_file_path = Path(r'\\\\192.168.10.106\\imdea\\DataDriven_UT_AlbertoVicente\\04_ML_data\\Juan Ignacio\\JI_4\\MonoElement\\patch_vs_volfrac_3.csv')\n",
    "\n",
    "df2 = pd.read_csv(dataset_file_path)\n",
    "\n",
    "# Count the number of rows\n",
    "rows = len(df2)\n",
    "\n",
    "# Select different measurements to associate with this dataset\n",
    "registration_ids = [26]\n",
    "\n",
    "datasettype_id = 2  # Assuming dataset type ID is 1, replace with actual ID if needed\n",
    "\n",
    "# Define different dataset parameters\n",
    "patch_size = \"32x32\"\n",
    "targets = [\"density\", \"thickness\"]\n",
    "reconstruction_shape = (512, 512)\n",
    "description = \"Advanced dataset with additional metadata\"\n",
    "\n",
    "# Define additional metadata\n",
    "additional_metadata = [\n",
    "    {'key': 'preprocessing', 'value': 'normalized', 'type': 'string'},\n",
    "    {'key': 'feature_extraction', 'value': 'wavelet transform', 'type': 'string'},\n",
    "    {'key': 'augmentation', 'value': 'True', 'type': 'boolean'},\n",
    "    {'key': 'train_test_split', 'value': '0.8', 'type': 'ratio'},\n",
    "    {'key': 'author', 'value': 'Data Science Team', 'type': 'string'}\n",
    "]\n",
    "\n",
    "# Load the dataset with additional metadata\n",
    "dataset_id = load.load_dataset(\n",
    "    conn, \n",
    "    datasettype_id,\n",
    "    str(dataset_file_path),\n",
    "    rows, \n",
    "    patch_size, \n",
    "    targets, \n",
    "    reconstruction_shape, \n",
    "    registration_ids,\n",
    "    description,\n",
    "    additional_metadata\n",
    ")\n",
    "\n",
    "print(f\"Dataset with additional metadata loaded with ID: {dataset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b0f8e1",
   "metadata": {},
   "source": [
    "## Verify Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3e55e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset basic information:\n",
      "+---+------------+---------------------------------------------------------------------------------------------------------------------+-------------------------------------------+\n",
      "|   | id_dataset |                                                  file_path_dataset                                                  |            description_dataset            |\n",
      "+---+------------+---------------------------------------------------------------------------------------------------------------------+-------------------------------------------+\n",
      "| 0 |     66     | \\\\192.168.10.106\\imdea\\DataDriven_UT_AlbertoVicente\\04_ML_data\\Juan Ignacio\\JI_4\\MonoElement\\patch_vs_volfrac_3.csv | Advanced dataset with additional metadata |\n",
      "+---+------------+---------------------------------------------------------------------------------------------------------------------+-------------------------------------------+\n",
      "\n",
      "Dataset-registrations relationships:\n",
      "+---+------------+---------------------------------------------------------------------------------------------------------------------+-------------------------------------------+------------------------+---------------+--------------------+------------------------------+-----------------------+----------------------------+----------------------+--------------------------+--------------------------+-------------------+-----------------+---------------------------------------+----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+\n",
      "|   | id_dataset |                                                  file_path_dataset                                                  |            description_dataset            | datasettype_id_dataset | rows_dataset  | patch_size_dataset | reconstruction_shape_dataset | preprocessing_dataset | feature_extraction_dataset | augmentation_dataset | train_test_split_dataset |      author_dataset      |  target_dataset   | id_registration | reference_measurement_id_registration | registered_measurement_id_registration |                                                          registration_matrix_registration                                                          |                                                                                                             type_registration                                                                                                             | axes_registration |\n",
      "+---+------------+---------------------------------------------------------------------------------------------------------------------+-------------------------------------------+------------------------+---------------+--------------------+------------------------------+-----------------------+----------------------------+----------------------+--------------------------+--------------------------+-------------------+-----------------+---------------------------------------+----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+\n",
      "| 0 |     66     | \\\\192.168.10.106\\imdea\\DataDriven_UT_AlbertoVicente\\04_ML_data\\Juan Ignacio\\JI_4\\MonoElement\\patch_vs_volfrac_3.csv | Advanced dataset with additional metadata |           2            | 2686 cardinal |    32x32 pixels    |   (512, 512) pixels tuple    |   normalized string   |  wavelet transform string  |      True bool       |        0.8 ratio         | Data Science Team string | thickness nominal |       26        |                  94                   |                  107                   | [[0.9997319637593441, -0.023151687581795338, -778.0071270155852], [0.02315168758179534, 0.9997319637593441, -166.30577187017394], [0.0, 0.0, 1.0]] | Alberto 2024 registration method, UTvsXCTPreprocessing toolkit 0.1.14 , file register.py function register_ut_xct_monoelement. Extract the centers of the holes from UT and XCT, and register them using a rigid body transformation text |  ['x', 'y'] list  |\n",
      "+---+------------+---------------------------------------------------------------------------------------------------------------------+-------------------------------------------+------------------------+---------------+--------------------+------------------------------+-----------------------+----------------------------+----------------------+--------------------------+--------------------------+-------------------+-----------------+---------------------------------------+----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "# Get dataset data from the database\n",
    "dataset_data = qrs.get_data_metadata('datasets')\n",
    "\n",
    "# Display the dataset data\n",
    "print(\"Dataset basic information:\")\n",
    "print(tabulate(dataset_data[['id_dataset', 'file_path_dataset', 'description_dataset']].tail(), \n",
    "               headers='keys', tablefmt='pretty'))\n",
    "\n",
    "# Get relationship data\n",
    "relationship_data = qrs.relation_metadata('datasets', 'registrations', 'dataset_registrations')\n",
    "\n",
    "# Display relationships\n",
    "print(\"\\nDataset-registrations relationships:\")\n",
    "print(tabulate(relationship_data.tail(), headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edfcc993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database connection\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
